{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EMBmSKNOCS3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f173e9bb-2fd3-477b-a12d-6ff85fe41cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.22.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yffRouwj5krX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cbc9c3-c699-43e4-bf1e-1afb53543852"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ARnCYQRnvXcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8352eb2-d686-4b76-bb23-2a479032c3da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current selenium version is: 4.14.0\n",
            "/usr/lib/chromium-browser/chromedriver\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import selenium\n",
        "import gspread\n",
        "import time\n",
        "import random\n",
        "print(\"Current selenium version:\", selenium.__version__)\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import deque\n",
        "from urllib.parse import urlsplit\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import multiprocessing\n",
        "import difflib\n",
        "import sys\n",
        "from google.auth import exceptions\n",
        "from google.oauth2 import service_account\n",
        "!ls /usr/lib/chromium-browser/chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920, 1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver"
      ],
      "metadata": {
        "id": "EkQUCA2mum8E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def email1(url):\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    time.sleep(4)\n",
        "    new_emails = set(re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,4}\", response.text, re.I))\n",
        "    # email_info+= ', '.join(new_emails)\n",
        "    # emails.update(new_emails)\n",
        "    return new_emails\n",
        "  except (requests.exceptions.MissingSchema, requests.exceptions.ConnectionError):\n",
        "    print('have error')\n",
        "    return"
      ],
      "metadata": {
        "id": "nBI2N8Gzuq-P"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "A1X5kzkYwOZI"
      },
      "outputs": [],
      "source": [
        "def get_email(website, link_contact) :\n",
        "  if type(website) != None:\n",
        "    email_info = \"\"\n",
        "    original_url = link_contact\n",
        "    # save urls to be scraped\n",
        "    unscraped = deque([original_url])\n",
        "    ### to save scraped urls\n",
        "    scraped = set()\n",
        "    ### to save fetched emails\n",
        "    emails = set()\n",
        "    email_pattern = r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,4}\"\n",
        "    html = driver.page_source\n",
        "    try:\n",
        "      while len(unscraped):\n",
        "          url = unscraped.popleft()\n",
        "          scraped.add(url)\n",
        "          parts = urlsplit(url)\n",
        "          base_url = \"{0.scheme}://{0.netloc}\".format(parts)\n",
        "          if '/' in parts.path:\n",
        "              path = url[:url.rfind('/') + 1]\n",
        "          else:\n",
        "              path = url\n",
        "          print(\"Crawling URL %s\" % url)\n",
        "\n",
        "          start_time = time.time()\n",
        "          process = multiprocessing.Process(target=email1,args=(url,))\n",
        "          process.start()\n",
        "          process.join(timeout=10)  # Wait at most 10 secs\n",
        "          if process.is_alive():\n",
        "              print(\"Over 10 secs, skip.\")\n",
        "              continue\n",
        "          else:\n",
        "              end_time = time.time()\n",
        "              temp_emails = email1(url)\n",
        "              email_info+= ', '.join(temp_emails)\n",
        "              emails.update(temp_emails)\n",
        "\n",
        "    except Exception as e:\n",
        "      print('00001')\n",
        "      email_pattern = r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,4}\"\n",
        "      html = driver.page_source\n",
        "      emails = re.findall(email_pattern, html)\n",
        "      email_info += ', '.join(emails)\n",
        "      return email_info\n",
        "    isEmpty = (len(emails) == 0) # Check if email is detected\n",
        "    if isEmpty:\n",
        "        email_pattern = r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,4}\"\n",
        "        html = driver.page_source\n",
        "        emails = re.findall(email_pattern, html)\n",
        "        email_info += ', '.join(emails)\n",
        "        return email_info\n",
        "    else:\n",
        "        return email_info\n",
        "    driver.delete_all_cookies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "lLI5J-IrwRTm"
      },
      "outputs": [],
      "source": [
        "def get_url_company(driver,key_word):\n",
        "  driver.get('https://www.google.com/search?&hl=en')\n",
        "  driver.find_element(By.NAME, \"q\").send_keys(key_word + \" \" + \"website\" + Keys.ENTER)\n",
        "  time.sleep(3)\n",
        "  # soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  # time.sleep(3)\n",
        "  # website = soup.find('div', class_=\"yuRUbf\")\n",
        "  # link = website.a.get('href')\n",
        "  first_div_element = driver.find_elements(By.XPATH,'//div[@class=\"yuRUbf\"]')\n",
        "  if first_div_element:\n",
        "    best_match_link = None\n",
        "    best_match_ratio = 0\n",
        "    # Check each <div> element\n",
        "    print('###########start')\n",
        "    for div_element in first_div_element:\n",
        "      span_elements = div_element.find_elements(By.TAG_NAME, 'a')\n",
        "      if span_elements:\n",
        "        for span in span_elements:\n",
        "          link = span.get_attribute('href')\n",
        "          if 'linked' not in link and 'facebook'not in link and 'wiki'not in link and 'wmb'not in link :\n",
        "            # Calculate ratio between actual company name vs link\n",
        "            similarity_ratio = difflib.SequenceMatcher(None, key_word.lower(), link.lower()).ratio()\n",
        "            if len(link) <= 40 and similarity_ratio > best_match_ratio:\n",
        "                best_match_link = link\n",
        "                best_match_ratio = similarity_ratio\n",
        "    if best_match_link:\n",
        "      print(key_word)\n",
        "      print(best_match_link)\n",
        "    print('###########end')\n",
        "  return best_match_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Xv3wnQnIwU_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26031a77-2d3d-4b80-9cca-4e31a4c75681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company Name\n",
            "FinditParts\n",
            "###########start\n",
            "FinditParts\n",
            "https://www.finditparts.com/\n",
            "###########end\n",
            "Crawling URL https://www.finditparts.com/contact#:~:text=Contact%20the%20FinditParts%20Team&text=Give%20us%20a%20call%20at,7am%20EST%20%2D%207pm%20EST%20weekdays.\n",
            "Error occurred : 2\n"
          ]
        }
      ],
      "source": [
        "driver = web_driver()\n",
        "err=''\n",
        "url_sheet ='https://docs.google.com/spreadsheets/d/1lkQE12IVMfiNJAAuwUj7jMIWamDp-nqYu-9D7waPPmc/edit?usp=sharing'\n",
        "try :\n",
        "  json_keyfile = 'authen.json'\n",
        "  # Access READ and WRITE permission\n",
        "  scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "  # Authenticize with JSON Service Account Key\n",
        "  credentials = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile, scope)\n",
        "except Exception as e:\n",
        "  err='0'\n",
        "  print('miss authentication file, please add file')\n",
        "try :\n",
        "  gc = gspread.authorize(credentials)\n",
        "  sh = gc.open_by_url(url_sheet)\n",
        "  # If it is the first sheet then pass 0 as the parameter, and so on\n",
        "  worksheet = sh.get_worksheet(0)\n",
        "  # Read data from file, excluding the header line\n",
        "  data = worksheet.get_all_values()[1:]\n",
        "  column_names = worksheet.row_values(1)\n",
        "  # Find the location of the column named \"Company Name\"\n",
        "  Company_column_index = None\n",
        "  for i, column_name in enumerate(column_names):\n",
        "      if column_name == \"Company Name\":\n",
        "          print(column_name)\n",
        "          Company_column_index = i + 1\n",
        "  if Company_column_index is not None:\n",
        "    # Get at values in Company Name column\n",
        "    test_column_values = worksheet.col_values(Company_column_index)\n",
        "    # Remove titles\n",
        "    test_column_values = test_column_values[1:]\n",
        "  else:\n",
        "      print(\"Could not find 'test' column in sheet.\")\n",
        "      err='1'\n",
        "      sys.exit()\n",
        "  temp = 1\n",
        "  for row in test_column_values:\n",
        "    print(row)\n",
        "    temp +=1\n",
        "    try :\n",
        "      website_url = get_url_company(driver,row)\n",
        "      driver.get('https://www.google.com/search?&hl=en')\n",
        "      driver.find_element(By.NAME, \"q\").send_keys(row + \" \" + \"contact\" + Keys.ENTER)\n",
        "      time.sleep(3)\n",
        "      soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "      website = soup.find('div', class_=\"yuRUbf\")\n",
        "      link = website.a.get('href')\n",
        "      email_web = get_email(website,link)\n",
        "      for i in range(3,5):\n",
        "        if i == 3:\n",
        "          if website_url:\n",
        "            worksheet.update_cell(temp, i, website_url)\n",
        "          else:\n",
        "            worksheet.update_cell(temp, i, 'empty')\n",
        "        if i==4:\n",
        "          if row:\n",
        "            worksheet.update_cell(temp, i, email_web)\n",
        "          else:\n",
        "            worksheet.update_cell(temp, i, 'empty')\n",
        "    except Exception as e:\n",
        "      err='2'\n",
        "      worksheet.update_cell(temp, 5, str(e))\n",
        "      pass\n",
        "except Exception as e:\n",
        "  pass\n",
        "  print(f\"Error occurred : {err}\")\n",
        "driver.quit()"
      ]
    }
  ]
}